{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "e:\\TU\\SoSe24\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import codecs\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from num2words import num2words\n",
    "\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data exploration and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read text files safely\n",
    "def read_text_file(file_path):\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sentences = file.readlines()\n",
    "    return sentences\n",
    "\n",
    "# Function to calculate most frequent word\n",
    "def most_frequent_word(text):\n",
    "    words = text.split()\n",
    "    word_freq = Counter(words)\n",
    "    return word_freq.most_common(1)[0][0]\n",
    "\n",
    "# Function to calculate unique words count\n",
    "def count_unique_words(text):\n",
    "    words = text.split()\n",
    "    return len(set(words))\n",
    "\n",
    "# Function to calculate numeral frequencies\n",
    "def count_numerals(text):\n",
    "    numeral_count = Counter(char for char in text if char.isdigit())\n",
    "    return numeral_count\n",
    "\n",
    "# File paths\n",
    "en_file_path = 'de-en/europarl-v7.de-en.en'  # English language file\n",
    "de_file_path = 'de-en/europarl-v7.de-en.de'  # German language file\n",
    "\n",
    "# Read the files\n",
    "en_sentences = read_text_file(en_file_path)\n",
    "de_sentences = read_text_file(de_file_path)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'en': en_sentences, 'de': de_sentences})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "num_sentences = len(df)\n",
    "en_lengths = df['en'].str.len()\n",
    "de_lengths = df['de'].str.len()\n",
    "length_diff = en_lengths - de_lengths\n",
    "\n",
    "# Calculate total number of words, unique words, and average word length\n",
    "def calculate_word_stats(text):\n",
    "    words = text.split()\n",
    "    num_words = len(words)\n",
    "    unique_words = count_unique_words(text)\n",
    "    avg_word_length = sum(len(word) for word in words) / num_words\n",
    "    return num_words, unique_words, avg_word_length\n",
    "\n",
    "en_num_words, unique_en_words, awl_en = calculate_word_stats(' '.join(df['en']))\n",
    "de_num_words, unique_de_words, awl_de = calculate_word_stats(' '.join(df['de']))\n",
    "\n",
    "# Calculate most frequent words\n",
    "most_freq_word_en = most_frequent_word(' '.join(df['en']))\n",
    "most_freq_word_de = most_frequent_word(' '.join(df['de']))\n",
    "\n",
    "# Calculate numeral frequencies\n",
    "numeral_freq_en = count_numerals(' '.join(df['en']))\n",
    "numeral_freq_de = count_numerals(' '.join(df['de']))\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = [\n",
    "    ['Number of sentences', num_sentences],\n",
    "    ['Total words (English)', en_num_words],\n",
    "    ['Total words (German)', de_num_words],\n",
    "    ['Unique words (English)', unique_en_words],\n",
    "    ['Unique words (German)', unique_de_words],\n",
    "    ['Average word length (English)', awl_en],\n",
    "    ['Average word length (German)', awl_de],\n",
    "    ['Average sentence length (English)', en_lengths.mean()],\n",
    "    ['Average sentence length (German)', de_lengths.mean()],\n",
    "    ['Average sentence length difference (English - German)', length_diff.mean()],\n",
    "    ['Most frequent word (English)', most_freq_word_en],\n",
    "    ['Most frequent word (German)', most_freq_word_de]\n",
    "    #['Numerals frequency (English)', numeral_freq_en],\n",
    "    #['Numerals frequency (German)', numeral_freq_de]\n",
    "]\n",
    "\n",
    "# Print summary statistics\n",
    "print(tabulate(summary_stats, headers=['Statistic', 'Value'], tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display word clouds\n",
    "def generate_word_cloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Create word clouds for English and German text\n",
    "generate_word_cloud(' '.join(df['en']), 'Most Common Words in English')\n",
    "generate_word_cloud(' '.join(df['de']), 'Most Common Words in German')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en_sentence_length'] = df['en'].str.len()\n",
    "df['de_sentence_length'] = df['de'].str.len()\n",
    "\n",
    "df['en_num_words'] = df['en'].str.split().apply(len)\n",
    "df['de_num_words'] = df['de'].str.split().apply(len)\n",
    "\n",
    "df['en_avg_word_length'] = df['en_sentence_length'] / df['en_num_words']\n",
    "df['de_avg_word_length'] = df['de_sentence_length'] / df['de_num_words']\n",
    "\n",
    "# Plotting with Seaborn\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Distribution of Average Word Length\n",
    "plt.subplot(1, 1, 1)\n",
    "sns.histplot(df['en_avg_word_length'], kde=True, color='blue', label='English')\n",
    "sns.histplot(df['de_avg_word_length'], kde=True, color='green', label='German')\n",
    "plt.title('Distribution of Average Word Length')\n",
    "plt.xlabel('Average Word Length (Characters)')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 10% of the data\n",
    "df_sampled = df.sample(frac=0.10, random_state=42)\n",
    "\n",
    "# Preprocessing steps\n",
    "def preprocess_text(df, column, lang, replacements):\n",
    "    df[column] = df[column].str.lower()\n",
    "    df[column] = df[column].apply(remove_number_lists)\n",
    "    df[column] = df[column].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    df[column] = df[column].apply(remove_specific_characters, args=(replacements,))\n",
    "    df[column] = df[column].apply(remove_whitespace_before_numbers)\n",
    "    df[column] = df[column].apply(remove_report_number)\n",
    "    df[column] = df[column].apply(lambda x: ' '.join(x.split()))\n",
    "    df[column] = df[column].apply(convert_numbers_to_words, args=(lang,))\n",
    "    return df\n",
    "\n",
    "def remove_number_lists(text):\n",
    "    pattern = r'\\b\\d+(?:,\\s*\\d+)*\\b'\n",
    "    return re.sub(pattern, '', text).strip()\n",
    "\n",
    "def remove_specific_characters(text, replacements):\n",
    "    for key, value in replacements.items():\n",
    "        text = text.replace(key, value)\n",
    "    text = re.sub(r'[-„“‟”–…‘’´­•—‚‘υπέρœ―]', '', text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_whitespace_before_numbers(text):\n",
    "    return re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text)\n",
    "\n",
    "def remove_report_number(text):\n",
    "    text = re.sub(r'\\b[a-z]\\d+\\b', '', text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def convert_numbers_to_words(sentence, lang='en'):\n",
    "    words = word_tokenize(sentence)\n",
    "    converted_words = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            number = int(word)\n",
    "            if 0 <= number <= 999999999:\n",
    "                converted_words.append(num2words(number, lang=lang))\n",
    "            else:\n",
    "                converted_words.append(word)\n",
    "        except (ValueError, NotImplementedError):\n",
    "            converted_words.append(word)\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "def write_files(df):\n",
    "    columns_to_save = {'en': 'en.txt', 'de': 'de.txt'}\n",
    "    for column, filename in columns_to_save.items():\n",
    "        df[column].to_csv(filename, index=False, header=False, encoding='utf-8')\n",
    "    print(\"Columns have been saved to separate files.\")\n",
    "\n",
    "# Define replacements for 'en' and 'de'\n",
    "replacements = {\n",
    "    'en': {'½': 'one half', '¾': 'three quarters', '£': 'pound', '°': 'degree', '§': 'section'},\n",
    "    'de': {'½': 'ein halb', '¾': 'drei viertel', '€': 'euro', '°': 'grad', '§': 'abschnitt'}\n",
    "}\n",
    "\n",
    "# Apply preprocessing to 'en' and 'de' columns\n",
    "df_sampled = preprocess_text(df_sampled, 'en', 'en', replacements['en'])\n",
    "df_sampled = preprocess_text(df_sampled, 'de', 'de', replacements['de'])\n",
    "\n",
    "# Strip empty lines and their correspondences\n",
    "df_sampled = df_sampled[(df_sampled['en'].str.strip() != '') & (df_sampled['de'].str.strip() != '')]\n",
    "\n",
    "# Write the processed data to files\n",
    "write_files(df_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 10 % of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  de  \\\n",
      "0  rückwürfe von bis zu zwei millionen tonnen ges...   \n",
      "1  ferner zeigt sie nützliche marktinstrumente zu...   \n",
      "2  dies bringt jedoch auch höhere kosten für die ...   \n",
      "3            bedeutende reaktionsfähigkeit potenzial   \n",
      "4  ein tätigwerden auf dem gebiet der vermarktung...   \n",
      "\n",
      "                                                  en  \n",
      "0  discarding nearly two million tonnes of health...  \n",
      "1  they can also point out useful market instrume...  \n",
      "2   however it will mean more costs for the consumer  \n",
      "3                   significant reactivity potential  \n",
      "4  the need for action on the marketing of constr...  \n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess data\n",
    "with open(\"de.txt\", 'r', encoding='utf-8') as file1: \n",
    "    de_texts = [line.strip() for line in file1]\n",
    "with open(\"en.txt\", 'r', encoding='utf-8') as file2: \n",
    "    en_texts = [line.strip() for line in file2]\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "df_sampled = pd.DataFrame({'de': de_texts, 'en': en_texts})\n",
    "df_sampled = df_sampled.sample(frac=0.05, random_state=1).reset_index(drop=True)\n",
    "df_sampled.tail()\n",
    "print(df_sampled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data. 20% test and rest into train and val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (7006, 2)\n",
      "Validation data shape: (610, 2)\n",
      "Test data shape: (1904, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>wir werden ab mai eine gemeinschaft mit millio...</td>\n",
       "      <td>from the first of may we shall be a community ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>bericht von frau maría rodríguez ramos im name...</td>\n",
       "      <td>report by maría rodríguez ramos on behalf of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>für das europäische projekt von morgen sind wi...</td>\n",
       "      <td>for the european project of the future we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>schriftlich sv der bericht über die gemeinsame...</td>\n",
       "      <td>in writing sv the report on the common agricul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>frauen und mädchen werden unterdrückt insbeson...</td>\n",
       "      <td>women and girls suffer oppression particularly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     de  \\\n",
       "4997  wir werden ab mai eine gemeinschaft mit millio...   \n",
       "5944  bericht von frau maría rodríguez ramos im name...   \n",
       "9334  für das europäische projekt von morgen sind wi...   \n",
       "2102  schriftlich sv der bericht über die gemeinsame...   \n",
       "7075  frauen und mädchen werden unterdrückt insbeson...   \n",
       "\n",
       "                                                     en  \n",
       "4997  from the first of may we shall be a community ...  \n",
       "5944  report by maría rodríguez ramos on behalf of t...  \n",
       "9334  for the european project of the future we are ...  \n",
       "2102  in writing sv the report on the common agricul...  \n",
       "7075  women and girls suffer oppression particularly...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 0.2  # 20% for test set\n",
    "train_val_df, test_df = train_test_split(df_sampled, test_size=test_size, random_state=42)\n",
    "\n",
    "# Further split train/validation:\n",
    "val_size = 0.08  # 8% of remaining data for validation\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size, random_state=42)\n",
    "\n",
    "print(\"Train data shape:\", train_df.shape)\n",
    "print(\"Validation data shape:\", val_df.shape)\n",
    "print(\"Test data shape:\", test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DatasetDict from train_df, val_df and test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['de', 'en', '__index_level_0__'],\n",
      "        num_rows: 7006\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['de', 'en', '__index_level_0__'],\n",
      "        num_rows: 610\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['de', 'en', '__index_level_0__'],\n",
      "        num_rows: 1904\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrames to Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# Print the DatasetDict\n",
    "print(dataset)\n",
    "\n",
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize train, val and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7006/7006 [00:03<00:00, 1988.41 examples/s]\n",
      "Map: 100%|██████████| 610/610 [00:00<00:00, 2217.93 examples/s]\n",
      "Map: 100%|██████████| 1904/1904 [00:00<00:00, 2874.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
    "\n",
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"de_nlp\": de_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 'wir werden ab mai eine gemeinschaft mit millionen menschen sein',\n",
       " 'en': 'from the first of may we shall be a community of million people',\n",
       " '__index_level_0__': 4997,\n",
       " 'en_tokens': ['<sos>',\n",
       "  'from',\n",
       "  'the',\n",
       "  'first',\n",
       "  'of',\n",
       "  'may',\n",
       "  'we',\n",
       "  'shall',\n",
       "  'be',\n",
       "  'a',\n",
       "  'community',\n",
       "  'of',\n",
       "  'million',\n",
       "  'people',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'wir',\n",
       "  'werden',\n",
       "  'ab',\n",
       "  'mai',\n",
       "  'eine',\n",
       "  'gemeinschaft',\n",
       "  'mit',\n",
       "  'millionen',\n",
       "  'menschen',\n",
       "  'sein',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vocabularies with words and special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get indices of special tokens and set return index for non existing word in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<unk>', '<pad>', '<sos>', '<eos>', 'die', 'der', 'und', 'in'],\n",
       " ['<unk>', '<pad>', '<sos>', '<eos>', 'the', 'of', 'to', 'and'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)\n",
    "x = 8\n",
    "\n",
    "de_vocab.get_itos()[:x], en_vocab.get_itos()[:x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchtext.vocab.vocab.Vocab, 4437, 5335)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(de_vocab), len(en_vocab), len(de_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 7006/7006 [00:01<00:00, 4918.86 examples/s]\n",
      "Map: 100%|██████████| 610/610 [00:00<00:00, 4895.12 examples/s]\n",
      "Map: 100%|██████████| 1904/1904 [00:00<00:00, 4964.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    # Convert token lists to their corresponding indices\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}\n",
    "\n",
    "# Dictionary of keyword arguments for the function\n",
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "# Apply the numericalization function to each split of the dataset\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datasets.arrow_dataset.Dataset,\n",
       " {'de': 'wir werden ab mai eine gemeinschaft mit millionen menschen sein',\n",
       "  'en': 'from the first of may we shall be a community of million people',\n",
       "  '__index_level_0__': 4997,\n",
       "  'en_tokens': ['<sos>',\n",
       "   'from',\n",
       "   'the',\n",
       "   'first',\n",
       "   'of',\n",
       "   'may',\n",
       "   'we',\n",
       "   'shall',\n",
       "   'be',\n",
       "   'a',\n",
       "   'community',\n",
       "   'of',\n",
       "   'million',\n",
       "   'people',\n",
       "   '<eos>'],\n",
       "  'de_tokens': ['<sos>',\n",
       "   'wir',\n",
       "   'werden',\n",
       "   'ab',\n",
       "   'mai',\n",
       "   'eine',\n",
       "   'gemeinschaft',\n",
       "   'mit',\n",
       "   'millionen',\n",
       "   'menschen',\n",
       "   'sein',\n",
       "   '<eos>'],\n",
       "  'en_ids': [2, 37, 4, 102, 5, 170, 13, 264, 18, 10, 175, 5, 341, 80, 3],\n",
       "  'de_ids': [2, 11, 22, 347, 1048, 20, 297, 23, 316, 117, 73, 3]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indices of words as torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert ids to torch tensors\n",
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([  2,  37,   4, 102,   5, 170,  13, 264,  18,  10, 175,   5, 341,  80,\n",
       "           3]),\n",
       " 'de_ids': tensor([   2,   11,   22,  347, 1048,   20,  297,   23,  316,  117,   73,    3]),\n",
       " 'de': 'wir werden ab mai eine gemeinschaft mit millionen menschen sein',\n",
       " 'en': 'from the first of may we shall be a community of million people',\n",
       " '__index_level_0__': 4997,\n",
       " 'en_tokens': ['<sos>',\n",
       "  'from',\n",
       "  'the',\n",
       "  'first',\n",
       "  'of',\n",
       "  'may',\n",
       "  'we',\n",
       "  'shall',\n",
       "  'be',\n",
       "  'a',\n",
       "  'community',\n",
       "  'of',\n",
       "  'million',\n",
       "  'people',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'wir',\n",
       "  'werden',\n",
       "  'ab',\n",
       "  'mai',\n",
       "  'eine',\n",
       "  'gemeinschaft',\n",
       "  'mit',\n",
       "  'millionen',\n",
       "  'menschen',\n",
       "  'sein',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "# All the German sentences will have length x and all the English sentences will have length y in each batch\n",
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders with collate_fn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will give DataLoaders based on provided dataset\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crate data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN based seq2seq architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=False)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "\n",
    "encoder_embedding_dim = 300\n",
    "decoder_embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(tqdm(data_loader)):\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(data_loader)):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "\n",
    "            output = model(src, trg, 0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe Embedding Matrices. Train with GloVe embeddings. Evaluate with GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "# Create glove embedding matrices\n",
    "def load_glove_embeddings(glove_file, vocab: Vocab, embedding_dim: int):\n",
    "    # Initialize the embedding matrix with small random values using PyTorch\n",
    "    embedding_matrix = torch.randn((len(vocab), embedding_dim)) * 0.01\n",
    "    \n",
    "    # Load pre-trained GloVe embeddings\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            word = parts[0]\n",
    "            if word in vocab:  # Check if the word is in the vocabulary\n",
    "                idx = vocab.get_stoi()[word]\n",
    "                embedding_vector = torch.tensor([float(val) for val in parts[1:]], dtype=torch.float32)\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "    \n",
    "    # Initialize special token embeddings\n",
    "    # 0: '<unk>', 1: '<pad>', 2: '<sos>', 3: '<eos>'\n",
    "    embedding_matrix[0] = torch.randn(embedding_dim) * 0.1  # Small random values for unknown\n",
    "    embedding_matrix[1] = torch.zeros(embedding_dim)  # Zero initialization for padding token\n",
    "    embedding_matrix[2] = torch.randn(embedding_dim) * 0.1  # Small random values (sos)\n",
    "    embedding_matrix[3] = torch.randn(embedding_dim) * 0.1  # Small random values (eos)\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_dim = 300\n",
    "en_glove_file = 'glove.6B.300d.txt'\n",
    "de_glove_file = 'glove.de.txt' # https://www.deepset.ai/german-word-embeddings\n",
    "\n",
    "# en_gembedding_matrix = load_glove_embeddings(en_glove_file, en_vocab, embedding_dim)\n",
    "# de_gembedding_matrix = load_glove_embeddings(de_glove_file, de_vocab, embedding_dim)\n",
    "\n",
    "# Save the embedding matrices\n",
    "# torch.save(en_gembedding_matrix, 'embeddings/en_gembedding_matrix.pt')\n",
    "# torch.save(de_gembedding_matrix, 'embeddings/de_gembedding_matrix.pt')\n",
    "\n",
    "# Load the embedding matrices\n",
    "en_gembedding_matrix = torch.load('embeddings/en_gembedding_matrix.pt')\n",
    "de_gembedding_matrix = torch.load('embeddings/de_gembedding_matrix.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train German to English model with GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:37<00:00,  2.96it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.268 | Train PPL: 527.170\n",
      "\tValid Loss:   5.917 | Valid PPL: 371.213\n",
      "Batch 1 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.001 | Train PPL: 403.797\n",
      "\tValid Loss:   5.897 | Valid PPL: 364.125\n",
      "Batch 2 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:36<00:00,  3.00it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.933 | Train PPL: 377.150\n",
      "\tValid Loss:   5.861 | Valid PPL: 350.966\n",
      "Batch 3 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.06it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.793 | Train PPL: 327.941\n",
      "\tValid Loss:   5.848 | Valid PPL: 346.639\n",
      "Batch 4 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.06it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.675 | Train PPL: 291.367\n",
      "\tValid Loss:   5.815 | Valid PPL: 335.327\n",
      "Batch 5 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.13it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.578 | Train PPL: 264.486\n",
      "\tValid Loss:   5.793 | Valid PPL: 327.941\n",
      "Batch 6 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.511 | Train PPL: 247.472\n",
      "\tValid Loss:   5.771 | Valid PPL: 320.759\n",
      "Batch 7 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:36<00:00,  3.02it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.445 | Train PPL: 231.605\n",
      "\tValid Loss:   5.763 | Valid PPL: 318.288\n",
      "Batch 8 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.07it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.395 | Train PPL: 220.257\n",
      "\tValid Loss:   5.782 | Valid PPL: 324.425\n",
      "Batch 9 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.14it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.349 | Train PPL: 210.501\n",
      "\tValid Loss:   5.747 | Valid PPL: 313.133\n",
      "Batch 10 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Load our preptrained GloVe embeddings\n",
    "encoder.embedding.weight.data.copy_(de_gembedding_matrix)\n",
    "decoder.embedding.weight.data.copy_(en_gembedding_matrix)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"models/word_model_glove_de_en.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "    print(f\"Batch {epoch+1} done \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate German to English with BLEU and ROUGH scores with GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 5.707 | Test PPL: 300.884 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"models/word_model_glove_de_en.pt\"))\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        hidden, cell = model.encoder(tensor)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('die betreffenden bestimmungen drohen den wettbewerb zu verzerren und könnten den handel zwischen der schweiz und der eu beeinträchtigen',\n",
       " 'the rules in question are liable to distort competition and may affect trade between switzerland and the eu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[1][\"de\"]\n",
    "expected_translation = test_data[1][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'of',\n",
       " 'the',\n",
       " '<unk>',\n",
       " 'of',\n",
       " 'the',\n",
       " 'the',\n",
       " '<unk>',\n",
       " 'of',\n",
       " 'the',\n",
       " 'the',\n",
       " '<unk>',\n",
       " 'of',\n",
       " 'the',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " '<unk>',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")\n",
    "\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1904/1904 [00:35<00:00, 53.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# Function to translate sentences from English to German\n",
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"de\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm(test_data)\n",
    "]\n",
    "\n",
    "# Format the predictions for BLEU evaluation\n",
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "references = [[example[\"en\"]] for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<unk> <unk> of the <unk> of the the <unk> of the the <unk> of the the of the <unk>',\n",
       " ['the rules in question are liable to distort competition and may affect trade between switzerland and the eu'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1], references[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the tokenizer\n",
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        # Split the text by spaces first to handle special tokens\n",
    "        tokens = s.split()\n",
    "        # Process each token using the NLP tokenizer, except for special tokens\n",
    "        processed_tokens = []\n",
    "        for token in tokens:\n",
    "            if token == \"<unk>\" or \"<sos>\" or \"<eos>\":\n",
    "                processed_tokens.append(token)\n",
    "            else:\n",
    "                processed_tokens.extend([tok.text for tok in nlp.tokenizer(token)])\n",
    "        \n",
    "        # Convert to lowercase if required\n",
    "        if lower:\n",
    "            processed_tokens = [token.lower() for token in processed_tokens]\n",
    "        return processed_tokens\n",
    "    return tokenizer_fn\n",
    "\n",
    "# Get the tokenizer function\n",
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the', '<unk>', 'of', 'the', '<unk>', 'of', 'the', '<unk>', 'of', 'the'],\n",
       " ['no',\n",
       "  'one',\n",
       "  'in',\n",
       "  'was',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'the',\n",
       "  'possible',\n",
       "  'consequences',\n",
       "  'of',\n",
       "  'instituting',\n",
       "  'the',\n",
       "  'policy',\n",
       "  'of',\n",
       "  'nonvaccination'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn(predictions[2]), tokenizer_fn(references[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sentence length and BLEU score: -0.01266811287556699\n"
     ]
    }
   ],
   "source": [
    "# Compute BLEU score for each sentence individually\n",
    "sentence_lengths = [len(example[\"de\"].split()) for example in test_data]\n",
    "sentence_bleu_scores = []\n",
    "\n",
    "for pred, ref in zip(predictions, references):\n",
    "    score = bleu.compute(predictions=[pred], references=[ref], tokenizer=tokenizer_fn)\n",
    "    sentence_bleu_scores.append(score[\"bleu\"])\n",
    "\n",
    "# Analyze the relationship between sentence length and BLEU score\n",
    "lengths_vs_scores = list(zip(sentence_lengths, sentence_bleu_scores))\n",
    "\n",
    "# Plot the data\n",
    "sns.scatterplot(x=sentence_lengths, y=sentence_bleu_scores)\n",
    "plt.xlabel(\"Sentence Length\")\n",
    "plt.ylabel(\"BLEU Score\")\n",
    "plt.title(\"Sentence Length vs BLEU Score\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = np.corrcoef(sentence_lengths, sentence_bleu_scores)[0, 1]\n",
    "print(f\"Correlation between sentence length and BLEU score: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.00623454451086874,\n",
       " 'precisions': [0.18863245120065358,\n",
       "  0.021409373165683216,\n",
       "  0.00206726825266612,\n",
       "  0.0008392195258409679],\n",
       " 'brevity_penalty': 0.6814461403307918,\n",
       " 'length_ratio': 0.7227845965667046,\n",
       " 'translation_length': 34273,\n",
       " 'reference_length': 47418}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute BLEU score for all sentences\n",
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores: {'rouge1': 0.15245915271630953, 'rouge2': 0.01723672796807622, 'rougeL': 0.14416754586185712}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Adjust the function to ensure `references` is a list of single strings\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Initialize score counters\n",
    "    scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "    count = len(predictions)\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Score method expects both pred and ref to be single strings\n",
    "        score = scorer.score(ref, pred)\n",
    "        for key in scores.keys():\n",
    "            scores[key] += score[key].fmeasure\n",
    "    \n",
    "    # Average scores\n",
    "    for key in scores.keys():\n",
    "        scores[key] /= count\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Prepare predictions and references\n",
    "# Ensure references are in string format\n",
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "references = [example[\"en\"] for example in test_data]  # Ensure this is a list of strings\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_scores = compute_rouge(predictions, references)\n",
    "print(f\"ROUGE scores: {rouge_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2vec embedding Matrices. <br>Train with Word2vec embeddings. <br>Evaluate with Word2vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"embeddings\", exist_ok=True)\n",
    "import gensim\n",
    "\n",
    "def load_word2vec_embeddings(word2vec_file, vocab, embedding_dim, binary=True):\n",
    "    # Initialize the embedding matrix with small random values using PyTorch\n",
    "    embedding_matrix = torch.randn((len(vocab), embedding_dim)) * 0.01\n",
    "    \n",
    "    # Get the string-to-index mapping from the vocabulary\n",
    "    stoi = vocab.get_stoi()\n",
    "    \n",
    "    if binary:\n",
    "        # Load the Word2Vec model from a binary file\n",
    "        word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_file, binary=True)\n",
    "        \n",
    "        # Iterate over each word in the Word2Vec model\n",
    "        for word in word2vec.key_to_index:\n",
    "            if word in vocab:  # Check if the word is in the vocabulary\n",
    "                idx = stoi[word]  # Get the index of the word in the vocabulary\n",
    "                embedding_matrix[idx] = torch.tensor(word2vec[word])  # Place the embedding at the correct index\n",
    "    else:\n",
    "        # Read the embeddings from the text file\n",
    "        with open(word2vec_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                # Remove the b' and ' from the word part\n",
    "                word = parts[0][2:-1]\n",
    "                vector = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float)\n",
    "                if word in vocab:  # Check if the word is in the vocabulary\n",
    "                    idx = stoi[word]  # Get the index of the word in the vocabulary\n",
    "                    embedding_matrix[idx] = vector  # Place the embedding at the correct index\n",
    "\n",
    "\n",
    "    # Initialize special token embeddings\n",
    "    # 0: '<unk>', 1: '<pad>', 2: '<sos>', 3: '<eos>'\n",
    "    embedding_matrix[0] = torch.randn(embedding_dim) * 0.1  # Small random values for unknown\n",
    "    embedding_matrix[1] = torch.zeros(embedding_dim)  # Zero initialization for padding token\n",
    "    embedding_matrix[2] = torch.randn(embedding_dim) * 0.1  # Small random values (sos)\n",
    "    embedding_matrix[3] = torch.randn(embedding_dim) * 0.1  # Small random values (eos)\n",
    "    \n",
    "    return torch.FloatTensor(embedding_matrix)\n",
    "\n",
    "# Example usage\n",
    "embedding_dim = 300\n",
    "en_word2vec_file = 'GoogleNews-vectors-negative300.bin'\n",
    "de_word2vec_file = 'word2vec.de.txt'\n",
    "\n",
    "# Assuming en_vocab and de_vocab are your vocabularies of type torchtext.vocab.Vocab\n",
    "# en_wembedding_matrix = load_word2vec_embeddings(en_word2vec_file, en_vocab, embedding_dim, binary=True)\n",
    "# de_wembedding_matrix = load_word2vec_embeddings(de_word2vec_file, de_vocab, embedding_dim, binary=False)\n",
    "\n",
    "# Save the embedding matrices\n",
    "# torch.save(en_wembedding_matrix, 'embeddings/en_wembedding_matrix.pt')\n",
    "# torch.save(de_wembedding_matrix, 'embeddings/de_wembedding_matrix.pt')\n",
    "\n",
    "# Load the embedding matrices\n",
    "en_wembedding_matrix = torch.load(\"embeddings/en_wembedding_matrix.pt\")\n",
    "de_wembedding_matrix = torch.load(\"embeddings/de_wembedding_matrix.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.10it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.772 | Train PPL: 321.109\n",
      "\tValid Loss:   5.762 | Valid PPL: 317.915\n",
      "Batch 1 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.16it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.449 | Train PPL: 232.432\n",
      "\tValid Loss:   5.747 | Valid PPL: 313.396\n",
      "Batch 2 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.13it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.342 | Train PPL: 208.895\n",
      "\tValid Loss:   5.726 | Valid PPL: 306.678\n",
      "Batch 3 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.20it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.285 | Train PPL: 197.371\n",
      "\tValid Loss:   5.725 | Valid PPL: 306.311\n",
      "Batch 4 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.14it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.217 | Train PPL: 184.344\n",
      "\tValid Loss:   5.740 | Valid PPL: 310.953\n",
      "Batch 5 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.18it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.197 | Train PPL: 180.684\n",
      "\tValid Loss:   5.744 | Valid PPL: 312.344\n",
      "Batch 6 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:33<00:00,  3.24it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.170 | Train PPL: 175.894\n",
      "\tValid Loss:   5.707 | Valid PPL: 301.047\n",
      "Batch 7 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.16it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.136 | Train PPL: 170.079\n",
      "\tValid Loss:   5.709 | Valid PPL: 301.604\n",
      "Batch 8 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:34<00:00,  3.23it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.112 | Train PPL: 165.953\n",
      "\tValid Loss:   5.708 | Valid PPL: 301.174\n",
      "Batch 9 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:35<00:00,  3.14it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.072 | Train PPL: 159.571\n",
      "\tValid Loss:   5.707 | Valid PPL: 300.982\n",
      "Batch 10 done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Load our preptrained word2vec embeddings\n",
    "encoder.embedding.weight.data.copy_(de_wembedding_matrix)\n",
    "decoder.embedding.weight.data.copy_(en_wembedding_matrix)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"models/word_model_word2vec_de_en.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "    print(f\"Batch {epoch+1} done \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate German to English with BLEU and ROUGH scores with Word2Vec embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 5.674 | Test PPL: 291.197 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"models/word_model_word2vec_de_en.pt\"))\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BLEU metric\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "# Function to translate sentences from English to German\n",
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"de\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm(test_data)\n",
    "]\n",
    "\n",
    "# Format the predictions for BLEU evaluation\n",
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "references = [[example[\"en\"]] for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the commission is the to be a <unk> of the <unk>',\n",
       " ['the commission is aware of the need to speed up the registration procedures'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[4], references[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the tokenizer\n",
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        # Split the text by spaces first to handle special tokens\n",
    "        tokens = s.split()\n",
    "        # Process each token using the NLP tokenizer, except for special tokens\n",
    "        processed_tokens = []\n",
    "        for token in tokens:\n",
    "            if token == \"<unk>\" or \"<sos>\" or \"<eos>\":\n",
    "                processed_tokens.append(token)\n",
    "            else:\n",
    "                processed_tokens.extend([tok.text for tok in nlp.tokenizer(token)])\n",
    "        \n",
    "        # Convert to lowercase if required\n",
    "        if lower:\n",
    "            processed_tokens = [token.lower() for token in processed_tokens]\n",
    "        return processed_tokens\n",
    "    return tokenizer_fn\n",
    "\n",
    "# Get the tokenizer function\n",
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEU score for each sentence individually\n",
    "sentence_lengths = [len(example[\"de\"].split()) for example in test_data]\n",
    "sentence_bleu_scores = []\n",
    "\n",
    "for pred, ref in zip(predictions, references):\n",
    "    score = bleu.compute(predictions=[pred], references=[ref], tokenizer=tokenizer_fn)\n",
    "    print(score)\n",
    "    sentence_bleu_scores.append(score[\"bleu\"])\n",
    "\n",
    "# Analyze the relationship between sentence length and BLEU score\n",
    "lengths_vs_scores = list(zip(sentence_lengths, sentence_bleu_scores))\n",
    "\n",
    "# Plot the data\n",
    "sns.scatterplot(x=sentence_lengths, y=sentence_bleu_scores)\n",
    "plt.xlabel(\"Sentence Length\")\n",
    "plt.ylabel(\"BLEU Score\")\n",
    "plt.title(\"Sentence Length vs BLEU Score\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation coefficient\n",
    "correlation = np.corrcoef(sentence_lengths, sentence_bleu_scores)[0, 1]\n",
    "print(f\"Correlation between sentence length and BLEU score: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.012715262754415757,\n",
       " 'precisions': [0.2176041219407471,\n",
       "  0.034421167352869944,\n",
       "  0.005685468328408069,\n",
       "  0.0025631386487133044],\n",
       " 'brevity_penalty': 0.6995480897333491,\n",
       " 'length_ratio': 0.7367455396684803,\n",
       " 'translation_length': 34935,\n",
       " 'reference_length': 47418}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute BLEU score for all sentences\n",
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores: {'rouge1': 0.17647781875396965, 'rouge2': 0.027024037433042027, 'rougeL': 0.16041948869390563}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Adjust the function to ensure `references` is a list of single strings\n",
    "def compute_rouge(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Initialize score counters\n",
    "    scores = {\"rouge1\": 0, \"rouge2\": 0, \"rougeL\": 0}\n",
    "    count = len(predictions)\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Score method expects both pred and ref to be single strings\n",
    "        score = scorer.score(ref, pred)\n",
    "        for key in scores.keys():\n",
    "            scores[key] += score[key].fmeasure\n",
    "    \n",
    "    # Average scores\n",
    "    for key in scores.keys():\n",
    "        scores[key] /= count\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Prepare predictions and references\n",
    "# Ensure references are in string format\n",
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "references = [example[\"en\"] for example in test_data]  # Ensure this is a list of strings\n",
    "\n",
    "# Compute ROUGE scores\n",
    "rouge_scores = compute_rouge(predictions, references)\n",
    "print(f\"ROUGE scores: {rouge_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
